Current Project State & Development Guide
Project Overview
A **Semi-Automated** Threat Modeling Pipeline application with a modern web interface for processing security documents through an AI-powered analysis pipeline with human review and quality control at each step.

âš ï¸ **IMPORTANT: This is NOT a fully automated pipeline**
- Each step requires human review and validation
- Users can edit, add, or remove extracted data before proceeding
- Quality control is provided by the user at each stage
- The AI assists but doesn't make final decisions
Current Architecture
Directory Structure
ThreatModelingPipeline/
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ api/                  # FastAPI backend (Python 3.11)
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”œâ”€â”€ api/endpoints/ # API routes
â”‚   â”‚   â”‚   â”œâ”€â”€ core/         # Business logic
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ llm/      # LLM providers (Ollama, Azure, Scaleway)
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ pipeline/ # Pipeline management
â”‚   â”‚   â”‚   â”‚       â””â”€â”€ steps/ # Individual pipeline steps
â”‚   â”‚   â”‚   â”œâ”€â”€ models/       # Data models
â”‚   â”‚   â”‚   â”œâ”€â”€ services/     # Service layer
â”‚   â”‚   â”‚   â””â”€â”€ config.py     # Settings management
â”‚   â”‚   â”œâ”€â”€ venv/             # Python virtual environment
â”‚   â”‚   â”œâ”€â”€ requirements.txt  # Python dependencies
â”‚   â”‚   â””â”€â”€ .env              # Environment variables
â”‚   â”‚
â”‚   â””â”€â”€ web/                  # Next.js frontend
â”‚       â”œâ”€â”€ app/              # Next.js app router
â”‚       â”œâ”€â”€ components/       # React components
â”‚       â”‚   â”œâ”€â”€ pipeline/steps/ # Step-specific components
â”‚       â”‚   â””â”€â”€ ui/           # Reusable UI components
â”‚       â”œâ”€â”€ lib/              # Utilities, API client, store
â”‚       â””â”€â”€ hooks/            # Custom React hooks
â”‚
â”œâ”€â”€ inputs/                   # Input documents for testing
â”œâ”€â”€ outputs/                  # Generated outputs
â”‚   â”œâ”€â”€ exports/
â”‚   â”œâ”€â”€ reports/
â”‚   â””â”€â”€ temp/
â”œâ”€â”€ docker-compose.yml        # Docker configuration
â””â”€â”€ package.json             # Root monorepo config
Tech Stack
Backend (FastAPI)

Python 3.11 with FastAPI
LLM Integration: Supports Ollama (local), Azure OpenAI, and Scaleway
Dependencies: Pydantic for validation, HTTPX for async requests
CORS configured for localhost:3000, 3001, 3002

Frontend (Next.js)

Next.js 14 with TypeScript
Styling: Tailwind CSS with custom dark theme
State Management: Zustand (lightweight alternative to Redux)
Icons: Lucide React
Running on port 3001 (3000 was occupied)

Infrastructure

Redis: Running in Docker for caching (optional)
Monorepo: Managed with npm workspaces

Pipeline Process Flow
1. **Document Upload** â†’ User uploads system documentation
2. **DFD Extraction** â†’ AI extracts components (requires manual trigger)
3. **DFD Review** â†’ User reviews/edits extracted data with:
   - JSON view for raw data inspection
   - Mermaid diagram view for visualization
   - Full editing capabilities for all components
4. **Threat Generation** â†’ AI generates threats (user reviews)
5. **Threat Refinement** â†’ User refines and validates threats
6. **Attack Path Analysis** â†’ AI analyzes attack paths (user validates)

Current Features
Working
âœ… Modern dark UI with purple/blue gradients
âœ… 6-step pipeline sidebar navigation (including DFD Review)
âœ… File upload interface with drag-and-drop
âœ… State management with Zustand including persistence
âœ… API structure with all endpoints implemented
âœ… Responsive layout with status panel
âœ… CORS configuration with dynamic origins
âœ… LLM provider factory with Scaleway, Azure, and Ollama support
âœ… DFD extraction with comprehensive prompting
âœ… Pipeline state management with in-memory storage
âœ… WebSocket endpoint structure
âœ… DFD visualization with JSON and Mermaid diagram tabs
âœ… Complete DFD editing interface with add/remove capabilities
âœ… Manual step progression (no automatic advancement)
Partially Working
âš ï¸ Threat generation logic (placeholder implementation)
âš ï¸ Document parsing for PDFs (basic) and DOCX (not implemented)
âš ï¸ Redis caching integration
Not Implemented Yet
âŒ Threat refinement algorithm
âŒ Attack path analysis
âŒ WebSocket real-time updates (structure only)
âŒ Database persistence (using in-memory storage)
âŒ Authentication and user sessions
âŒ Export functionality for reports
How to Add New Features
Method 1: Adding a New Pipeline Step

Update the type definitions in apps/web/lib/store.ts:

typescriptexport type PipelineStep = 
  | 'document_upload'
  | 'dfd_extraction' 
  | 'dfd_review'        // User review/edit of extracted DFD
  | 'threat_generation'
  | 'threat_refinement'
  | 'attack_path_analysis'
  | 'your_new_step'  // Add here

Add to backend pipeline manager in apps/api/app/core/pipeline/manager.py:

pythonclass PipelineStep(str, Enum):
    # ... existing steps
    YOUR_NEW_STEP = "your_new_step"

# Add handler in execute_step method
elif step == PipelineStep.YOUR_NEW_STEP:
    result = await self._handle_your_step(pipeline_id, step_num)

Update frontend UI in apps/web/app/page.tsx or component files:

typescriptconst steps = [
  // ... existing steps
  { id: 'your_new_step', name: 'Your Step', icon: YourIcon },
]
Method 2: Adding a New LLM Provider

Create provider class in apps/api/app/core/llm/your_provider.py:

pythonfrom app.core.llm.base import BaseLLMProvider, LLMResponse

class YourProvider(BaseLLMProvider):
    async def generate(self, prompt: str, system_prompt: Optional[str] = None) -> LLMResponse:
        # Implementation
        pass
    
    async def validate_connection(self) -> bool:
        # Check if provider is accessible
        pass

Update config in apps/api/app/config.py:

python# Add configuration fields
your_provider_api_key: Optional[str] = None
your_provider_endpoint: str = "https://api.your-provider.com"

Register in pipeline manager in apps/api/app/core/pipeline/manager.py:

pythonelif config["provider"] == "your_provider":
    return YourProvider(config)
Method 3: Adding UI Components

Create component file in apps/web/components/:

bashcat > components/your-component.tsx << 'EOF'
'use client'

export function YourComponent() {
  return (
    <div className="card-bg rounded-2xl p-6">
      {/* Component content */}
    </div>
  )
}
EOF

Import and use in pages:

typescriptimport { YourComponent } from '@/components/your-component'
Common Development Patterns
File Creation Pattern
Always use cat > filename << 'EOF' for creating files to avoid quote escaping issues:
bashcat > path/to/file.tsx << 'EOF'
// File content here
EOF
Styling Pattern
Use CSS variables defined in globals.css:

var(--bg-dark) - Main background
var(--bg-card) - Card backgrounds
var(--border-color) - Borders
.gradient-purple-blue - Gradient backgrounds
.card-bg - Card styling class

API Pattern
All API calls go through apps/web/lib/api.ts:
typescriptexport const api = {
  yourNewEndpoint: async (param: string) => {
    const response = await fetch(`${API_URL}/api/your-endpoint/${param}`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ data: 'value' })
    })
    return response.json()
  }
}
Running the Project
Development Mode
bash# Terminal 1 - Backend
cd apps/api
source venv/bin/activate
python -m uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# Terminal 2 - Frontend (runs on port 3001)
cd apps/web
npm run dev

# Terminal 3 - Redis (optional for caching)
docker run -d -p 6379:6379 redis:alpine

API Endpoints Available
- GET  /health - Health check
- GET  /docs - Interactive API documentation
- POST /api/documents/upload - Upload documents
- POST /api/pipeline/create - Create new pipeline
- POST /api/pipeline/{id}/execute/{step} - Execute specific step
- GET  /api/pipeline/{id}/status - Get pipeline status
- WS   /ws/{pipeline_id} - WebSocket for real-time updates
Common Issues & Fixes

Module not found errors: Check tsconfig.json has path aliases:

json"baseUrl": ".",
"paths": { "@/*": ["./*"] }

CORS errors: Ensure backend allows frontend origin in main.py
Styling not applying: Clear Next.js cache:

bashrm -rf .next
npm run dev
Next Steps for Completion

Implement document processing: Add actual file parsing in apps/api/app/api/endpoints/documents.py
Connect LLM providers: Add API keys to .env and test each provider
Add WebSocket updates: Implement real-time progress in apps/api/app/api/endpoints/websocket.py
Create result visualizations: Add components for displaying threats, DFDs, attack paths
Add authentication: Implement user sessions if needed
Deploy: Dockerize completely and deploy to cloud platform

Key Files Reference

Frontend entry: apps/web/app/page.tsx
API entry: apps/api/app/main.py
State management: apps/web/lib/store.ts
API client: apps/web/lib/api.ts
Pipeline logic: apps/api/app/core/pipeline/manager.py
DFD extraction: apps/api/app/core/pipeline/dfd_extraction_service.py
LLM providers: apps/api/app/core/llm/*.py
DFD Review UI: apps/web/components/pipeline/steps/dfd-review.tsx
Styling: apps/web/app/globals.css
Environment: apps/api/.env and apps/web/.env.local

This structure allows for modular development where features can be added incrementally without breaking existing functionality.

Recent Updates (Jan 2025):

âœ… Added DFD Review step to the pipeline
âœ… Implemented comprehensive DFD extraction service with LLM integration
âœ… Created Scaleway LLM provider with proper authentication
âœ… Fixed all Pydantic validation errors
âœ… Established proper module structure with __init__.py files
âœ… Updated pipeline manager with DFD review handler
âœ… Added WebSocket connection management in frontend
âœ… Implemented file upload validation and error handling
âœ… **NEW: Added DFD visualization with JSON and Mermaid diagram tabs**
âœ… **NEW: Implemented full DFD editing capabilities with add/remove functions**
âœ… **NEW: Added manual review requirement at each pipeline step**
âœ… **NEW: Created tabbed interface for viewing extracted data**

Previous Updates:

Perfect! I've fixed the Pydantic validation errors. The main issues were:
ğŸ“ What was fixed:

Updated config.py to include all the environment variables from your .env file
Added extra = "ignore" in the Config class to prevent validation errors for undefined fields
Updated the LLM provider factory to use settings object instead of os.getenv
Created all missing __init__.py files for proper Python module structure

ğŸ—‚ï¸ Required Directory Structure:
Make sure your directory structure looks like this:
apps/api/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py                    âœ… Created
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ config.py                      âœ… Fixed
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py                âœ… Created
â”‚   â”‚   â””â”€â”€ endpoints/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ documents.py
â”‚   â”‚       â”œâ”€â”€ pipeline.py
â”‚   â”‚       â”œâ”€â”€ websocket.py
â”‚   â”‚       â””â”€â”€ llm.py
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py                âœ… Created
â”‚   â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ollama.py
â”‚   â”‚   â”‚   â”œâ”€â”€ azure.py
â”‚   â”‚   â”‚   â””â”€â”€ scaleway.py
â”‚   â”‚   â””â”€â”€ pipeline/
â”‚   â”‚       â”œâ”€â”€ __init__.py            âœ… Created
â”‚   â”‚       â”œâ”€â”€ manager.py
â”‚   â”‚       â””â”€â”€ dfd_extraction_service.py
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ __init__.py                âœ… Created
â”‚       â””â”€â”€ dfd.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â””â”€â”€ venv/
ğŸš€ Now try running the backend again:
bashcd apps/api
source venv/bin/activate
python -m uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
The server should now start successfully! You should see:

INFO: Uvicorn running on http://0.0.0.0:8000
The API docs at http://localhost:8000/docs
Health check at http://localhost:8000/health

If you still get errors, they might be related to missing dependencies. Make sure you've installed all requirements:
bashpip install -r requirements.txt
The configuration now properly handles all your environment variables and won't throw validation errors.

Environment Variables Configuration

The .env file includes:
- LLM provider settings for Ollama, Azure OpenAI, and Scaleway
- Step-specific model configurations (STEP1_MODEL, STEP2_MODEL, etc.)
- Default provider selection per pipeline step
- CORS origins configuration (currently set to * for development)
- Redis URL for optional caching
- File upload limits and allowed extensions

Note: The Scaleway API key in the .env file appears to be active. Ensure this is properly secured and rotated regularly.
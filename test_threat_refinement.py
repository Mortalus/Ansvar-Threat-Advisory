#!/usr/bin/env python3
"""
Comprehensive test for AI-powered threat refinement system.
Tests the complete pipeline from document upload to refined threats.
"""
import requests
import json
import time

API_BASE = "http://localhost:8000"

def test_complete_refinement_pipeline():
    """Test the complete threat modeling and refinement pipeline."""
    
    print("üß† Testing AI-Powered Threat Refinement Pipeline")
    print("=" * 55)
    
    try:
        # Step 1: Upload test document with complexity
        test_document = """
        Financial Services Platform Architecture
        
        System Overview:
        Our platform handles sensitive financial transactions and customer data across multiple touchpoints.
        
        Components:
        
        1. Web Application Server
        - Handles customer login and account management
        - Processes transaction requests
        - Communicates with internal services via REST APIs
        - Stores session data in Redis cache
        
        2. Customer Database (PostgreSQL)
        - Stores customer PII, account balances, transaction history
        - Contains credit card information and SSNs
        - Encrypted at rest with TDE
        - Accessed only by authorized services
        
        3. Payment Processing Gateway
        - External third-party service (Stripe)
        - Processes credit card transactions
        - Handles PCI-DSS compliant payment flows
        - Returns transaction confirmations
        
        4. Authentication Service
        - Validates user credentials
        - Issues JWT tokens for session management
        - Integrates with MFA systems
        - Logs all authentication attempts
        
        5. Audit Logging System
        - Records all financial transactions
        - Stores security events and access logs
        - Required for regulatory compliance
        - Data retained for 7 years
        
        Data Flows:
        - Customer -> Web App (HTTPS, user credentials)
        - Web App -> Auth Service (internal API, credentials validation)
        - Web App -> Customer DB (encrypted connection, account queries)
        - Web App -> Payment Gateway (HTTPS, PCI-compliant data)
        - All services -> Audit System (encrypted logs)
        
        Trust Boundaries:
        - Internet-facing: Web Application Server
        - DMZ: Authentication Service, Payment Gateway
        - Internal Network: Customer Database, Audit System
        
        Security Controls:
        - WAF enabled on web application
        - TLS 1.3 for all communications
        - Database encryption at rest
        - Comprehensive logging and monitoring
        """
        
        files = {'files': ('finance_platform.txt', test_document, 'text/plain')}
        response = requests.post(f"{API_BASE}/api/documents/upload", files=files)
        response.raise_for_status()
        upload_data = response.json()
        pipeline_id = upload_data["pipeline_id"] 
        print(f"‚úì Document uploaded to pipeline: {pipeline_id}")
        print(f"  - Text length: {upload_data['text_length']} characters")
        
        # Step 2: Extract DFD
        print("\nüîç Extracting DFD components...")
        response = requests.post(f"{API_BASE}/api/documents/extract-dfd", 
                               json={"pipeline_id": pipeline_id})
        response.raise_for_status()
        dfd_data = response.json()
        
        components = dfd_data['dfd_components']
        print(f"‚úì DFD extracted:")
        print(f"  - Processes: {len(components.get('processes', []))}")
        print(f"  - Data Stores: {len(components.get('data_stores', []))}")
        print(f"  - External Entities: {len(components.get('external_entities', []))}")
        print(f"  - Data Flows: {len(components.get('data_flows', []))}")
        
        # Step 3: Review DFD (pass through for testing)
        print("\nüìã Reviewing DFD components...")
        response = requests.post(f"{API_BASE}/api/documents/review-dfd",
                               json={
                                   "pipeline_id": pipeline_id,
                                   "dfd_components": components
                               })
        response.raise_for_status()
        print("‚úì DFD review completed")
        
        # Step 4: Generate initial threats
        print("\n‚öîÔ∏è  Generating initial threats...")
        response = requests.post(f"{API_BASE}/api/documents/generate-threats",
                               json={"pipeline_id": pipeline_id})
        response.raise_for_status()
        threat_data = response.json()
        
        initial_threats = threat_data.get("threats", [])
        print(f"‚úì Generated {len(initial_threats)} initial threats")
        print(f"  - Components analyzed: {threat_data.get('components_analyzed', 0)}")
        
        # Show sample initial threat
        if initial_threats:
            sample = initial_threats[0]
            print(f"\nüìã Sample Initial Threat:")
            print(f"   Category: {sample.get('Threat Category', 'N/A')}")
            print(f"   Name: {sample.get('Threat Name', 'N/A')}")
            print(f"   Component: {sample.get('component_name', 'N/A')}")
            print(f"   Impact: {sample.get('Potential Impact', 'N/A')}")
            print(f"   Likelihood: {sample.get('Likelihood', 'N/A')}")
        
        # Step 5: AI-Powered Threat Refinement (The main test!)
        print(f"\nüß† Applying AI-powered threat refinement...")
        print("   - Semantic deduplication")
        print("   - Contextual risk assessment") 
        print("   - Business risk translation")
        print("   - Enhanced mitigation generation")
        print("   - Control-aware suppression")
        print("   - Priority scoring")
        
        response = requests.post(f"{API_BASE}/api/documents/refine-threats",
                               json={"pipeline_id": pipeline_id})
        
        if response.status_code == 200:
            refinement_data = response.json()
            refined_threats = refinement_data.get("refined_threats", [])
            stats = refinement_data.get("refinement_stats", {})
            
            print(f"‚úÖ THREAT REFINEMENT SUCCESSFUL!")
            print(f"   - Original threats: {stats.get('original_count', 0)}")
            print(f"   - Deduplicated: {stats.get('deduplicated_count', 0)} merged")
            print(f"   - Final refined threats: {len(refined_threats)}")
            
            # Show risk distribution
            risk_dist = stats.get('risk_distribution', {})
            print(f"\nüìä Risk Distribution:")
            for risk_level, count in risk_dist.items():
                print(f"   - {risk_level}: {count} threats")
            
            # Show enhanced threat example
            if refined_threats:
                print(f"\nüéØ Sample Refined Threat:")
                enhanced = refined_threats[0]
                print(f"   Category: {enhanced.get('Threat Category', 'N/A')}")
                print(f"   Name: {enhanced.get('Threat Name', 'N/A')}")
                print(f"   Component: {enhanced.get('component_name', 'N/A')}")
                print(f"   Risk Score: {enhanced.get('risk_score', 'N/A')}")
                print(f"   Priority Rank: #{enhanced.get('priority_rank', 'N/A')}")
                print(f"   Exploitability: {enhanced.get('exploitability', 'N/A')}")
                
                # Show business context enhancements
                if enhanced.get('business_risk_statement'):
                    print(f"   Business Risk: {enhanced.get('business_risk_statement', '')[:100]}...")
                
                if enhanced.get('primary_mitigation'):
                    print(f"   Primary Mitigation: {enhanced.get('primary_mitigation', '')[:100]}...")
                
                if enhanced.get('implementation_priority'):
                    print(f"   Implementation Priority: {enhanced.get('implementation_priority', 'N/A')}")
                
                if enhanced.get('estimated_effort'):
                    print(f"   Estimated Effort: {enhanced.get('estimated_effort', 'N/A')}")
                
                # Show AI-generated enhancements
                if enhanced.get('assessment_reasoning'):
                    print(f"   Assessment Reasoning: {enhanced.get('assessment_reasoning', '')[:150]}...")
            
            print(f"\nüéâ AI REFINEMENT FEATURES DEMONSTRATED:")
            print(f"   ‚úÖ LLM-powered semantic analysis")
            print(f"   ‚úÖ Contextual risk scoring") 
            print(f"   ‚úÖ Business impact translation")
            print(f"   ‚úÖ Enhanced mitigation recommendations")
            print(f"   ‚úÖ Intelligent prioritization")
            print(f"   ‚úÖ Quality filtering and deduplication")
            
            return True
            
        else:
            print(f"‚ùå REFINEMENT FAILED: Status {response.status_code}")
            print(f"Response: {response.text}")
            return False
            
    except Exception as e:
        print(f"‚ùå ERROR: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("Waiting for API to be ready...")
    time.sleep(5)
    
    success = test_complete_refinement_pipeline()
    
    if success:
        print("\nüéä AI-POWERED THREAT REFINEMENT TEST SUCCESSFUL!")
        print("\nKey Achievements:")
        print("‚Ä¢ LLM-based semantic deduplication working")
        print("‚Ä¢ Contextual risk assessment implemented")
        print("‚Ä¢ Business risk translation functioning")  
        print("‚Ä¢ Enhanced mitigation generation active")
        print("‚Ä¢ Intelligent threat prioritization operational")
        print("‚Ä¢ Full pipeline integration successful")
        print("\nThe AI-first threat refinement system is ready for production use!")
    else:
        print("\n‚ùå Test failed - check logs above")
    
    exit(0 if success else 1)